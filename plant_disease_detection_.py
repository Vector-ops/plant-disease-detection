# -*- coding: utf-8 -*-
"""Plant Disease detection .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xAabbdp6jmudz5bhOeOEL97rwCoke7bu

Made using Google colab https://colab.research.google.com/
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import keras
import os
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import img_to_array, load_img
from keras.applications.vgg19 import VGG19, preprocess_input, decode_predictions

from google.colab import drive
drive.mount('/content/drive')

"""To check no. of classes in train folder of dataset:"""

len(os.listdir('/content/drive/MyDrive/PlantDiseaseDataset/New Plant Diseases Dataset(Augmented)/train'))

"""# Pre-processing the dataset"""

# Data augmentation for training images
train_datagen = ImageDataGenerator(zoom_range = 0.5, shear_range = 0.3, horizontal_flip = True)

# Preprocessing for validation images
val_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)

# Creating training and validation data generators from the specified directory with data augmentation.

train = train_datagen.flow_from_directory(directory = "/content/drive/MyDrive/PlantDiseaseDataset/New Plant Diseases Dataset(Augmented)/train",
                                          target_size = (256, 256),
                                          batch_size = 32)

val = val_datagen.flow_from_directory(directory = "/content/drive/MyDrive/PlantDiseaseDataset/New Plant Diseases Dataset(Augmented)/valid",
                                          target_size = (256, 256),
                                          batch_size = 32)

"""Now we are done loading the dataset

# Visualizing some of our data
"""

t_img, label = train.next() # next() is used to load up the next batch of images for training

t_img.shape

"""
t_img has 32 images of 256 x 256 and 3 channel per image(RGB)"""

def plotImage(img_arr, label):
    for im, l in zip(img_arr, label):
        plt.figure(figsize = (5,5))
        plt.imshow(im/255)
        plt.show()

plotImage(t_img[:3], label[:3])

"""# Building the model"""

import keras
from keras.layers import Dense, Flatten
from keras.models import Model
from keras.applications.vgg19 import VGG19

#Creating a VGG19 base model
#VGG19 is a pre-defined CNN used for image classification
base_model = VGG19(input_shape=(256,256,3), include_top = False)

# Freeze all layers in the base model to prevent further training.
for layer in base_model.layers:
    layer.trainable=False

base_model.summary()

# Flatten the output of model to prepare for fully connected layers.
X = Flatten()(base_model.output)

# Add a fully connected layer with 38 units for classification using softmax activation.
X = Dense(units=38, activation='softmax')(X)

# Create our final model by combining the model and the new fully connected layer.
model = Model(base_model.input, X)

model.summary()

model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])

"""# Early stopping and model checkpoints"""

from keras.callbacks import ModelCheckpoint, EarlyStopping

# Early stopping: Stop training if validation accuracy does not improve by at least 0.01 for 3 consecutive epochs.
es = EarlyStopping(monitor = "val_accuracy",
                   min_delta = 0.01,
                   patience = 3,
                   verbose=1)

# Model checkpoint: Save the best model based on validation accuracy during training.
mc = ModelCheckpoint(filepath="best_model.h5",
                     monitor = "val_accuracy",
                     min_delta = 0.01,
                     patience = 3,
                     verbose = 1,
                     save_best_only = True)

# Combine early stopping and model checkpoint callbacks.
cb = [es, mc]

# Train the model on the training data using the specified callbacks.
his = model.fit(train,
                steps_per_epoch = 25,
                epochs = 50,
                verbose = 1,
                callbacks = cb,
                validation_data = val,
                validation_steps = 25)

"""Vizualizing the accuracy and loss of trained model(for reference):"""

# h = his.history
# h.keys()

# plt.plot(h['accuracy'])
# plt.plot(h['val_accuracy'], c = 'red')
# plt.title("acc vs val_acc")
# plt.xlim(0, 7)
# plt.ylim(0.4, 1)
# plt.legend(['accuracy', 'val_accuracy'])
# plt.show()

# plt.plot(h['loss'])
# plt.plot(h['val_loss'], c = 'red')
# plt.title("loss vs val_loss")
# # plt.xlim(0, 7)
# # plt.ylim(0.4, 1)
# plt.legend(['loss', 'val_loss'])
# plt.show()

from keras.models import load_model

# Load the pre-trained model from the "best_model.h5" file.
model = load_model("best_model.h5")

# Evaluate the model's accuracy on the validation data
# The "evaluate" method returns the loss value and the metrics specified during model compilation
# In this case, we are interested in the accuracy, which is at index 1 in the returned list
val_accuracy = model.evaluate(val)[1]

# Print the accuracy of the model on the validation data
print(f'The accuracy of the model on the validation data is {val_accuracy * 100:.2f}%')

# Creating a dictionary 'ref' that maps class indices to their corresponding class names from the 'train' data
ref = dict(zip(list(train.class_indices.values()), list(train.class_indices.keys())))

def prediction(path):
  # Load the image from the given path and resize it to 256x256 pixels
  img = load_img(path, target_size=(256, 256))

  # Convert the image to a NumPy array to prepare it for prediction
  i = img_to_array(img)

  # Preprocess the image using the same preprocessing applied during training
  im = preprocess_input(i)

  # Expand the dimensions of the preprocessed image to create a batch of one image
  img = np.expand_dims(im, axis=0)

  # Use the trained model to predict the class of the image
  pred = np.argmax(model.predict(img))

  # Print the predicted class name based on the mapping from 'ref'
  print(f'The image belongs to {ref[pred]}')

"""Dataset contains images for Apple, Cherry, Corn, Grape, Peach, Pepper, Potato, Strawberry, Tomato"""

path = "/content/drive/MyDrive/PlantDiseaseDataset/test/AppleCedarRust4.JPG"
prediction(path)